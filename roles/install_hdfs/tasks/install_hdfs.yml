---
# - name: Copy and Install Hadoop
#   become: yes
#   unarchive:
#     src: "{{ item }}"
#     dest: "{{ hadoop_home }}"
#     mode: 0755
#     extra_opts: [--strip-components=1]
#   with_items:
#     - "{{ hadoop_install_file }}"
#   when: 
#     - is_offline

- name: Set HDFS fact
  set_fact: hdfs_installed=True

- name: Create service account for HDFS
  user: 
    name: "{{ hadoop.user }}"
    system: yes
    shell: "{{ hadoop.user_shell }}"
    state: present
    groups: "{{hadoop.user_groups | join(',')}}"

- name: Define number of nodes
  set_fact: number_of_nodes="{{groups['hdfs-datanode'] | length | int }}"

- debug:
    msg: "Number of data nodes: {{ number_of_nodes }}"

- name: Disable HDFS replication in single node
  set_fact: hdfs_replication_factor=1
  when: number_of_nodes | int < 3

- name: Enable HDFS replication when cluster has more then three nodes
  set_fact: hdfs_replication_factor=3
  when: number_of_nodes | int >= 3

- debug:
    msg: "HDFS replication factor: {{ hdfs_replication_factor }}"

- name: Remove pre-existent hadoop data directory
  file:
    path: "{{ hadoop.data_dir }}/"
    state: absent
  become: true
  become_user: root

- name: create hadoop data directory
  file:
    path: "{{ hadoop.data_dir }}"
    state: directory
    owner: "{{ hadoop.user }}"
    group: "{{ hadoop.user }}"
  become: true

- name: Remove pre-existent hadoop name directory
  file:
    path: "{{ hadoop.name_dir }}"
    state: absent
  become: true
  become_user: root
  
  
- name: Create hadoop name directory
  file:
    path: "{{ hadoop.name_dir }}"
    state: directory
    owner: "{{ hadoop.user }}"
    group: "{{ hadoop.user }}"
  become: True

- name: Remove pre-existent hadoop temp directory
  file:
    path: "{{ hadoop.temp_dir }}"
    state: absent

- name: create hadoop temp directory
  file:
    path: "{{ hadoop.temp_dir }}"
    state: directory
    owner: "{{ hadoop.user }}"
    group: "{{ hadoop.user }}"
  become: true

- name: create install directory
  file:
    path: "{{ hadoop.install_dir }}"
    state: directory
    owner: "{{ hadoop.user }}"
    group: "{{ hadoop.user }}"
  become: true
  become_user: root


# Install Offline
- name: Copy and Install Hadoop with archive
  become: yes
  unarchive:
    src: "hadoop-{{ hadoop.version }}.tar.gz"
    dest: "{{ hadoop.install_dir }}"
    mode: 0755
    extra_opts: [--strip-components=1]
  when:
    - is_offline

# Install Online
- block: 
  - debug:
      msg: "Downloading Hadoop from: {{ hadoop.download_url }}/hadoop-{{ hadoop.version }}/{{ hadoop.archive }}"
  - name: Download hadoop
    get_url:
      url: "{{ hadoop.download_location }}/hadoop-{{ hadoop.version }}/{{ hadoop.hadoop_archive }}"
      dest: "{{ install_temp_dir }}/{{ hadoop.hadoop_archive }}"

  - name: unarchive to the install directory
    unarchive:
      src: "{{ install_temp_dir }}/{{ hadoop.hadoop_archive }}"
      dest: "{{ hadoop.install_dir }}"
      mode: 0755
      extra_opts: [--strip-components=1]
  when: not is_offline


# Setting configurations templates
- name: Create config directory
  file:
    path: "{{ hadoop.install_dir }}/etc/hadoop"
    state: directory
    owner: "{{ hadoop.user }}"
    group: "{{ hadoop.user }}"
  become: true

- name: set core-site.xml
  template:
    src: "core-site.xml.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/core-site.xml"

- name: set hadoop-env.sh
  template:
    src: "hadoop-env.sh.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/hadoop-env.sh"

- name: set hdfs-site.xml
  template: 
    src: "hdfs-site.xml.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/hdfs-site.xml"

- name: set mapred-site.xml
  template: 
    src: "mapred-site.xml.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/mapred-site.xml"

- name: set yarn-site.xml
  template: 
    src: "yarn-site.xml.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/yarn-site.xml"

- name: set slaves
  template:
    src: "slaves.j2"
    dest: "{{ hadoop.install_dir }}/etc/hadoop/slaves"
  become: true

# Environment setup.
- name: Clean hadoop profile
  file:
    path : /etc/profile.d/hadoop-profile.sh
    state: absent
  become: true
  become_user: root

- name: add hadoop profile to startup
  template:
    src: hadoop-profile.sh.j2
    dest: /etc/profile.d/hadoop-profile.sh
    mode: 0644
  become: true
  become_user: root

- name: format hdfs
  shell: "bin/hdfs namenode -format"
  args:
      chdir: "{{ hadoop.hadoop_home }}"
  when: inventory_hostname in groups['hdfs-namenode']


- name: "Starting HDFS daemons"
  ignore_errors: yes
  command: "{{ hadoop.hadoop_home}}/sbin/start-all.sh"
  become: true
  become_user: hadoop
  when: inventory_hostname in groups['hdfs-namenode']