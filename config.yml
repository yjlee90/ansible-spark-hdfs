# Essential
user_session: root
is_offline: true

ansible_user: root
ansible_ssh_private_key_file: ~/.ssh/id_rsa
gather_facts: True
gathering: smart
host_key_checking: False

# 
install_temp_dir: /tmp/ansible-install
install_dir: /opt

# Common
common:
  java:
    version: 8u291
    java_home: /opt/java/openjdk-8
    offline_archive_dir: '{{ playbook_dir }}/files'
    archive: "jdk-8u291-linux-x64.tar.gz"

# Hadoop
hadoop:
  version: 2.10.1
  # installation
  archive: "hadoop-2.10.1-src.tar.gz"
  download_url: https://archive.apache.org/dist/hadoop/common/
  install_dir: "/opt/hadoop/hadoop-2.10.1"
  # directories
  data_dir: /var/hadoop/data
  name_dir: /var/hadoop/name
  temp_dir: /tmp/hadoop/hdfs/tmp
  hadoop_home : /opt/hadoop/hadoop-2.10.1
  # users
  user: "hadoop"               # the name of the (OS)user created for spark
  user_groups: []             # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/bash"    # the hdfs user's default shell

spark:
  version: 2.4.7
  hadoop_version: 2.10.1
  install_dir: /opt/spark/spark-2.4.7
  working_dir: /tmp/spark/data
  spark_home: /opt/spark/spark-2.4.7
  master_port: 7077
  worker_work_port: 65000
  master_ui_port: 8080
  worker_ui_port: 8085
  download_location: https://archive.apache.org/dist/spark/
  user: "hadoop"               # the name of the (OS)user created for spark
  user_groups: []             # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/bash"    # the spark user's default shell

  env_extras: {}
  defaults_extras: {}
