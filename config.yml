# Essential
user_session: root
is_offline: true

# Ansible 
# ansible_connection: ssh
ansible_user: root
ansible_ssh_private_key_file: ~/.ssh/id_rsa
gather_facts: True
gathering: smart
host_key_checking: False

# JAVA
java_home: /opt/jdk/openjdk-8
jdk_install_file: "jdk-8u291-linux-x64.tar.gz"

# Installation
install_temp_dir: /tmp/ansible-install
install_dir: /opt

# Hadoop
#   server의 추가된 디스크에 설치를 한다.
hadoop_home : /opt/hadoop/hadoop-2.10.1
hadoop_install_file: "hadoop-2.10.1-src.tar.gz"

# Hadoop
hadoop:
  version: 2.10.1
  hadoop_archive: hadoop-2.10.1.tar.gz
  hadoop_install_dir: hadoop-2.10.1
  data_dir: /var/hadoop/data
  name_dir: /var/hadoop/name
  temp_dir: /tmp/hadoop/hdfs/tmp
  download_location: https://archive.apache.org/dist/hadoop/common/
  user: "hdfs"               # the name of the (OS)user created for spark
  user_groups: []             # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/false"    # the hdfs user's default shell
  re_install: True
  hadoop_home : /opt/hadoop/hadoop-2.10.1

spark:
  version: 2.4.7
  hadoop_version: 2.10.1
  spark_install_dir: spark-2.4.7
  working_dir: /tmp/spark/data
  master_port: 7077
  worker_work_port: 65000
  master_ui_port: 8080
  worker_ui_port: 8085
  download_location: https://archive.apache.org/dist/spark/
  user: "spark"               # the name of the (OS)user created for spark
  user_groups: []             # Optional list of (OS)groups the new spark user should belong to
  user_shell: "/bin/false"    # the spark user's default shell

  env_extras: {}
  defaults_extras: {}
