---
- hosts:
    - hdfs
  become_user: hadoop
  become: true 
  gather_facts: true 
  
  tasks:
    - name: include vars
      include_vars: "{{ playbook_dir }}/../config.yml"

    - name: check status
      command: "$JAVA_HOME/bin/jps"
      register: jps
    - debug : var=jps.stdout_lines

    - name: Start spark services 
      shell: "{{ item }}"
      ignore_errors: true
      become: true 
      become_user: hadoop
      with_items:
        - "bash {{ spark.spark_home }}/sbin/start-master.sh"
        - "bash {{ spark.spark_home }}/sbin/start-slaves.sh"
        - "bash {{ spark.spark_home }}/sbin/start-history-server.sh"
        - "bash {{ spark.spark_home }}/sbin/start-shuffle-service.sh"
      when: inventory_hostname in groups['spark-master']

    - name: check status
      command: "$JAVA_HOME/bin/jps"
      register: jps
    - debug : var=jps.stdout_lines

    # HDFS STOP ALL
    - name: start hadoop services
      command: "{{ item }}"
      ignore_errors: true
      with_items:
        - "{{ hadoop.hadoop_home }}/sbin/start-dfs.sh"
        - "{{ hadoop.hadoop_home }}/sbin/start-balancer.sh"
        - "{{ hadoop.hadoop_home }}/sbin/start-yarn.sh"
      when: inventory_hostname in groups['hdfs-namenode']

    - name: check status
      command: "$JAVA_HOME/bin/jps"
      register: jps
    - debug : var=jps.stdout_lines